{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Grams demo\n",
    "\n",
    "Here we use the nltk library to create n-grams.\n",
    "Its important to know how to install nltk though since we are using miniconda.\n",
    "\n",
    "From your terminal run:\n",
    "> conda activate <env name>\n",
    "\n",
    "> conda install -c anaconda nltk\n",
    "\n",
    "\n",
    "Once this is done, you will need to install nltk data.\n",
    "Open up the python terminal from within your conda environment.\n",
    "\n",
    "> python -m nltk.downloader all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk has a built-in function called split() that can be used but word_tokenizer handles things like punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kubernetes', 'is', 'an', 'open-source', 'platform', 'for', 'automating', 'the', 'deployment', ',', 'scaling', ',', 'and', 'management', 'of', 'containerized', 'applications', '.', 'It', 'provides', 'a', 'way', 'to', 'run', 'applications', 'in', 'a', 'consistent', ',', 'reliable', 'environment', ',', 'without', 'the', 'need', 'to', 'worry', 'about', 'the', 'underlying', 'infrastructure', '.']\n"
     ]
    }
   ],
   "source": [
    "s = \"Kubernetes is an open-source platform for automating the deployment, scaling, and management of containerized applications. It provides a way to run applications in a consistent, reliable environment, without the need to worry about the underlying infrastructure.\"\n",
    "tokenized_words = word_tokenize(s)\n",
    "print(tokenized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sent_tokenize function will tokenize based on sentences instead of words. Very handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kubernetes is an open-source platform for automating the deployment, scaling, and management of containerized applications.', 'It provides a way to run applications in a consistent, reliable environment, without the need to worry about the underlying infrastructure.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentences = sent_tokenize(s)\n",
    "print(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use the ngrams function to get the n-grams we need. Here we get bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kubernetes', 'is'),\n",
       " ('is', 'an'),\n",
       " ('an', 'open-source'),\n",
       " ('open-source', 'platform'),\n",
       " ('platform', 'for'),\n",
       " ('for', 'automating'),\n",
       " ('automating', 'the'),\n",
       " ('the', 'deployment'),\n",
       " ('deployment', ','),\n",
       " (',', 'scaling'),\n",
       " ('scaling', ','),\n",
       " (',', 'and'),\n",
       " ('and', 'management'),\n",
       " ('management', 'of'),\n",
       " ('of', 'containerized'),\n",
       " ('containerized', 'applications'),\n",
       " ('applications', '.'),\n",
       " ('.', 'It'),\n",
       " ('It', 'provides'),\n",
       " ('provides', 'a'),\n",
       " ('a', 'way'),\n",
       " ('way', 'to'),\n",
       " ('to', 'run'),\n",
       " ('run', 'applications'),\n",
       " ('applications', 'in'),\n",
       " ('in', 'a'),\n",
       " ('a', 'consistent'),\n",
       " ('consistent', ','),\n",
       " (',', 'reliable'),\n",
       " ('reliable', 'environment'),\n",
       " ('environment', ','),\n",
       " (',', 'without'),\n",
       " ('without', 'the'),\n",
       " ('the', 'need'),\n",
       " ('need', 'to'),\n",
       " ('to', 'worry'),\n",
       " ('worry', 'about'),\n",
       " ('about', 'the'),\n",
       " ('the', 'underlying'),\n",
       " ('underlying', 'infrastructure'),\n",
       " ('infrastructure', '.')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(tokenized_words, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we get trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kubernetes', 'is', 'an'),\n",
       " ('is', 'an', 'open-source'),\n",
       " ('an', 'open-source', 'platform'),\n",
       " ('open-source', 'platform', 'for'),\n",
       " ('platform', 'for', 'automating'),\n",
       " ('for', 'automating', 'the'),\n",
       " ('automating', 'the', 'deployment'),\n",
       " ('the', 'deployment', ','),\n",
       " ('deployment', ',', 'scaling'),\n",
       " (',', 'scaling', ','),\n",
       " ('scaling', ',', 'and'),\n",
       " (',', 'and', 'management'),\n",
       " ('and', 'management', 'of'),\n",
       " ('management', 'of', 'containerized'),\n",
       " ('of', 'containerized', 'applications'),\n",
       " ('containerized', 'applications', '.'),\n",
       " ('applications', '.', 'It'),\n",
       " ('.', 'It', 'provides'),\n",
       " ('It', 'provides', 'a'),\n",
       " ('provides', 'a', 'way'),\n",
       " ('a', 'way', 'to'),\n",
       " ('way', 'to', 'run'),\n",
       " ('to', 'run', 'applications'),\n",
       " ('run', 'applications', 'in'),\n",
       " ('applications', 'in', 'a'),\n",
       " ('in', 'a', 'consistent'),\n",
       " ('a', 'consistent', ','),\n",
       " ('consistent', ',', 'reliable'),\n",
       " (',', 'reliable', 'environment'),\n",
       " ('reliable', 'environment', ','),\n",
       " ('environment', ',', 'without'),\n",
       " (',', 'without', 'the'),\n",
       " ('without', 'the', 'need'),\n",
       " ('the', 'need', 'to'),\n",
       " ('need', 'to', 'worry'),\n",
       " ('to', 'worry', 'about'),\n",
       " ('worry', 'about', 'the'),\n",
       " ('about', 'the', 'underlying'),\n",
       " ('the', 'underlying', 'infrastructure'),\n",
       " ('underlying', 'infrastructure', '.')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(tokenized_words, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3be9f4e732ed8d2a8432346c901c2b4ddfa1bf0276b798dd80c83031cff82228"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
